{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e082744f",
   "metadata": {},
   "source": [
    "# Doc-GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c738d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7fe247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca429dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b212ed",
   "metadata": {},
   "source": [
    "## a model that gives you answer about a specific text you are providing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8c0121",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe_qa = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", device=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "262b5079",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa={\n",
    "    \"question\":\"What happened?\",\n",
    "    \"context\": \"A yellow warning for thunderstorms was in place for south-east England, parts of the south coast and London until 15:00 GMT on Tuesday. It follows stormy conditions across northern England and Scotland, with gusts of more than 70mph (112.7km/h) recorded in Wales and Northern Ireland. Debi is the fourth named storm of this winter so far. \\\n",
    "The rain and wind first hit Northern Ireland and the Republic of Ireland, then Wales, before moving eastwards and into the North Sea on Monday evening.\\\n",
    "In Northern Ireland, the storm caused road closures and some disruption to the public transport network. NIE Networks said about 3,000 customers were without power, mainly around Craigavon, Newry and Downpatrick.\\\n",
    "On Tuesday afternoon, the Environment Agency had 15 flood warnings in place - meaning flooding is expected - and 102 lesser flood alerts.\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3130858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.005024711135774851,\n",
       " 'start': 511,\n",
       " 'end': 593,\n",
       " 'answer': 'the storm caused road closures and some disruption to the public transport network'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_qa(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45d96e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the storm caused road closures and some disruption to the public transport network'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_qa_answer = pipe_qa(qa)[\"answer\"]\n",
    "pipe_qa_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234323b3",
   "metadata": {},
   "source": [
    "## a model for summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "730cdb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ba8065c46a498ba9f735ced4526c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c026a6fbd31042f0914480002833d251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/611M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2387b66932d54a6cafdec49fd7f3a98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b050c7d8ba9b45e99ed1e9b9f83df7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3f30b72428475d8c332eb0644f1758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe_summary = pipeline(\"summarization\", model=\"sshleifer/distilbart-xsum-12-6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7536ee73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Storm Debi has brought heavy rain and wind to parts of the UK.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_summary(\"A yellow warning for thunderstorms was in place for south-east England, parts of the south coast and London until 15:00 GMT on Tuesday. It follows stormy conditions across northern England and Scotland, with gusts of more than 70mph (112.7km/h) recorded in Wales and Northern Ireland. Debi is the fourth named storm of this winter so far. \\\n",
    "The rain and wind first hit Northern Ireland and the Republic of Ireland, then Wales, before moving eastwards and into the North Sea on Monday evening.\\\n",
    "In Northern Ireland, the storm caused road closures and some disruption to the public transport network. NIE Networks said about 3,000 customers were without power, mainly around Craigavon, Newry and Downpatrick.\\\n",
    "On Tuesday afternoon, the Environment Agency had 15 flood warnings in place - meaning flooding is expected - and 102 lesser flood alerts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e9cae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pipe_summary(\"A yellow warning for thunderstorms was in place for south-east England, parts of the south coast and London until 15:00 GMT on Tuesday. It follows stormy conditions across northern England and Scotland, with gusts of more than 70mph (112.7km/h) recorded in Wales and Northern Ireland. Debi is the fourth named storm of this winter so far. \\\n",
    "The rain and wind first hit Northern Ireland and the Republic of Ireland, then Wales, before moving eastwards and into the North Sea on Monday evening.\\\n",
    "In Northern Ireland, the storm caused road closures and some disruption to the public transport network. NIE Networks said about 3,000 customers were without power, mainly around Craigavon, Newry and Downpatrick.\\\n",
    "On Tuesday afternoon, the Environment Agency had 15 flood warnings in place - meaning flooding is expected - and 102 lesser flood alerts.\")[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c794f1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Storm Debi has brought heavy rain and wind to parts of the UK.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b50e83",
   "metadata": {},
   "source": [
    "## a model to give you answers about a specific document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0496cda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at impira/layoutlm-invoices were not used when initializing LayoutLMForQuestionAnswering: ['token_classifier_head.bias', 'token_classifier_head.weight']\n",
      "- This IS expected if you are initializing LayoutLMForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe_mm = pipeline(\"document-question-answering\", model=\"impira/layoutlm-invoices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f8a92fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe_mm_new = pipeline(\"document-question-answering\", model=\"impira/layoutlm-document-qa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2069ac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytesseract                       0.3.13\r\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f3f974",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9964991211891174, 'answer': '$2.89', 'start': 23, 'end': 23}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_mm(\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/lectures/Transformers/receipt.webp\",\n",
    "    \"How much was the eggs cost?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6820504",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mm = pipeline(\"document-question-answering\", model=\"impira/layoutlm-invoices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "350cd28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9975128769874573, 'answer': '$2.89', 'start': 23, 'end': 23}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_mm_new(\"/Users/carlobarbini/code/Karlobyo/doc_gpt_project/Doc_GPT/docs/receipt.png\", \n",
    "       \"How much was the eggs cost?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325d8ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_mm_new(\"/Users/carlobarbini/code/Karlobyo/doc_gpt_project/Doc_GPT_WEB/docs/new_pic.jpg\", \n",
    "       \"How much was the eggs cost?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed3dc7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to impira/layoutlm-document-qa and revision 52e01b3 (https://huggingface.co/impira/layoutlm-document-qa).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c253612702864837a691ca033459de2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/511M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n"
     ]
    }
   ],
   "source": [
    "#from docquery import pipeline\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize the pipeline\n",
    "#pipe_mm = pipeline('document-question-answering')\n",
    "\n",
    "# Load the image using PIL\n",
    "image_path = \"/Users/carlobarbini/code/Karlobyo/doc_gpt_project/Doc_GPT/docs/report.png\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Define your question\n",
    "question = \"How much was the eggs cost?\"\n",
    "\n",
    "# Call the pipeline\n",
    "try:\n",
    "    result = pipe_mm(image, question)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7e820",
   "metadata": {},
   "source": [
    "This is the only conversational model I found from Hugging Face..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "310c25be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " They are a group of people who are in charge of the physical, emotional, social, and intellectual development of a person.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "\n",
    "# Load BlenderBot model and tokenizer\n",
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Interact with BlenderBot\n",
    "inputs = tokenizer(\"What are menstruations?\", return_tensors=\"pt\")\n",
    "reply_ids = model.generate(**inputs)\n",
    "print(tokenizer.decode(reply_ids[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cfa50b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26cef1ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docquery\n",
      "  Downloading docquery-0.0.7-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch>=1.0 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from docquery) (2.4.0)\n",
      "Collecting pdf2image (from docquery)\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pdfplumber (from docquery)\n",
      "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: Pillow in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from docquery) (10.4.0)\n",
      "Requirement already satisfied: pydantic in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from docquery) (2.8.2)\n",
      "Requirement already satisfied: pytesseract in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from docquery) (0.3.13)\n",
      "Requirement already satisfied: requests in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from docquery) (2.32.3)\n",
      "Collecting easyocr (from docquery)\n",
      "  Downloading easyocr-1.7.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers>=4.23 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from docquery) (4.44.2)\n",
      "Requirement already satisfied: filelock in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from torch>=1.0->docquery) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from torch>=1.0->docquery) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from torch>=1.0->docquery) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from torch>=1.0->docquery) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from torch>=1.0->docquery) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from torch>=1.0->docquery) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from transformers>=4.23->docquery) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from transformers>=4.23->docquery) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from transformers>=4.23->docquery) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from transformers>=4.23->docquery) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from transformers>=4.23->docquery) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from transformers>=4.23->docquery) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from transformers>=4.23->docquery) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from transformers>=4.23->docquery) (4.66.5)\n",
      "Collecting torchvision>=0.5 (from easyocr->docquery)\n",
      "  Downloading torchvision-0.19.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.0 kB)\n",
      "Collecting opencv-python-headless (from easyocr->docquery)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from easyocr->docquery) (1.14.1)\n",
      "Collecting scikit-image (from easyocr->docquery)\n",
      "  Downloading scikit_image-0.24.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from easyocr->docquery)\n",
      "  Downloading python_bidi-0.6.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.6 kB)\n",
      "Collecting Shapely (from easyocr->docquery)\n",
      "  Downloading shapely-2.0.6-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Collecting pyclipper (from easyocr->docquery)\n",
      "  Downloading pyclipper-1.3.0.post5-cp310-cp310-macosx_10_9_universal2.whl.metadata (9.0 kB)\n",
      "Collecting ninja (from easyocr->docquery)\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-macosx_10_9_universal2.macosx_10_9_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl.metadata (5.3 kB)\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber->docquery)\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber->docquery)\n",
      "  Downloading pypdfium2-4.30.0-py3-none-macosx_11_0_arm64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber->docquery) (3.3.2)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20231228->pdfplumber->docquery)\n",
      "  Downloading cryptography-43.0.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from pydantic->docquery) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from pydantic->docquery) (2.20.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from requests->docquery) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from requests->docquery) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from requests->docquery) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from jinja2->torch>=1.0->docquery) (2.1.5)\n",
      "Collecting imageio>=2.33 (from scikit-image->easyocr->docquery)\n",
      "  Downloading imageio-2.35.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr->docquery)\n",
      "  Downloading tifffile-2024.8.24-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->easyocr->docquery)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from sympy->torch>=1.0->docquery) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber->docquery) (1.17.0)\n",
      "Requirement already satisfied: pycparser in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber->docquery) (2.22)\n",
      "Downloading docquery-0.0.7-py3-none-any.whl (35 kB)\n",
      "Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
      "Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.19.0-cp310-cp310-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-macosx_10_9_universal2.macosx_10_9_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl (270 kB)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-macosx_10_9_universal2.whl (277 kB)\n",
      "Downloading python_bidi-0.6.0-cp310-cp310-macosx_11_0_arm64.whl (250 kB)\n",
      "Downloading scikit_image-0.24.0-cp310-cp310-macosx_12_0_arm64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.6-cp310-cp310-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-43.0.0-cp39-abi3-macosx_10_9_universal2.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.35.1-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2024.8.24-py3-none-any.whl (225 kB)\n",
      "Installing collected packages: python-bidi, pyclipper, ninja, tifffile, Shapely, pypdfium2, pdf2image, opencv-python-headless, lazy-loader, imageio, scikit-image, cryptography, torchvision, pdfminer.six, pdfplumber, easyocr, docquery\n",
      "Successfully installed Shapely-2.0.6 cryptography-43.0.0 docquery-0.0.7 easyocr-1.7.1 imageio-2.35.1 lazy-loader-0.4 ninja-1.11.1.1 opencv-python-headless-4.10.0.84 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.4 pyclipper-1.3.0.post5 pypdfium2-4.30.0 python-bidi-0.6.0 scikit-image-0.24.0 tifffile-2024.8.24 torchvision-0.19.0\n"
     ]
    }
   ],
   "source": [
    "! pip install docquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb36d45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic==1.8.2\n",
      "  Downloading pydantic-1.8.2-py3-none-any.whl.metadata (103 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/carlobarbini/.pyenv/versions/3.10.6/envs/doc-gpt-env/lib/python3.10/site-packages (from pydantic==1.8.2) (4.12.2)\n",
      "Downloading pydantic-1.8.2-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "Successfully installed pydantic-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pydantic==1.8.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e6e22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U diffusers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e13068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b5aaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /Users/carlobarbini/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Use your actual Hugging Face API token here\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71786a19",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2051495608.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    prompt,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import FluxPipeline\n",
    "\n",
    "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-dev\", torch_dtype=torch.bfloat16)\n",
    "pipe.enable_model_cpu_offload() #save some VRAM by offloading the model to CPU. Remove this if you have enough GPU power\n",
    "\n",
    "prompt = \"A cat holding a sign that says hello world\"\n",
    "#image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=3.5,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512, \n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "#image.save(\"flux-dev.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee8c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af58c63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7d0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e716070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b18eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc7d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2614bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa7a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a600fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc1035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800fc4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
